{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  Fraud  \n",
       "0                       4.745402      0  False  \n",
       "1                       4.921349      0  False  \n",
       "2                       4.742303      0  False  \n",
       "3                       4.745402      0  False  \n",
       "4                       4.876771      0  False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fraud']=df['Label']==1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Fraud'].values \n",
    "X= df.drop(['Fraud','transactionAmount','Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "## Estandarizamos los valores de las variables continuas\n",
    "scaler  =  StandardScaler ()\n",
    "\n",
    "X_train_ = scaler.fit_transform(X_train)\n",
    "X_test_ = scaler.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear',C=1e9,random_state=42)\n",
    "logreg.fit(X_train_, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = logreg.predict(X_test_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of a logistic regression: 0.994112982675349\n",
      "f1 score of a logistic regression: 0.0\n",
      "fbeta score of a logistic regression: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy_logistic=accuracy_score(y_test, y_pred_log)\n",
    "f1_logistic=f1_score(y_test,y_pred_log,average='binary')\n",
    "fbs_logistic=fbeta_score(y_test,y_pred_log,average='binary', beta = 10 )\n",
    "\n",
    "print(\"Accuracy score of a logistic regression:\",accuracy_logistic)\n",
    "print(\"f1 score of a logistic regression:\", f1_logistic)\n",
    "print(\"fbeta score of a logistic regression:\", fbs_logistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4,max_leaf_nodes=10,random_state=42)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of a tree: 0.9940649253910662\n",
      "f1 score of a tree: 0.03891050583657587\n",
      "fbeta score of a tree: 0.020602154046997386\n"
     ]
    }
   ],
   "source": [
    "accuracy_tree=accuracy_score(y_test, y_pred_tree)\n",
    "f1_tree=f1_score(y_test,y_pred_tree,average='binary')\n",
    "fbs_tree=fbeta_score(y_test,y_pred_tree,average='binary', beta = 10 )\n",
    "\n",
    "print(\"Accuracy score of a tree:\",accuracy_tree)\n",
    "print(\"f1 score of a tree:\", f1_tree)\n",
    "print(\"fbeta score of a tree:\", fbs_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observaciones  138721\n",
      "Casos sin fraude  137924\n",
      "Casos con fraude  797\n"
     ]
    }
   ],
   "source": [
    "n_samples = df.shape[0]\n",
    "print('observaciones ',n_samples)\n",
    "n_samples_0 = (df['Label'] == 0).sum()\n",
    "print('Casos sin fraude ',n_samples_0)\n",
    "n_samples_1 = (df['Label'] == 1).sum()\n",
    "print('Casos con fraude ',n_samples_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El alto accuracy score y el bajo f1 score son los esperados debido a que la base está desbalanceada, tal como se mostró en la línea de código anterior. Por lo tanto, es necesario encontrar una forma de balancear la base de datos, ya sea utilizando over-sampling o under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9883220799192638\n",
      "f1 score of a logistic regression: 0.04330708661417323\n",
      "fbeta score of a logistic regression: 0.04486532326454791\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9788547949155393\n",
      "f1 score of a logistic regression: 0.05172413793103448\n",
      "fbeta score of a logistic regression: 0.09625541039590199\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9664800442127015\n",
      "f1 score of a logistic regression: 0.049079754601226995\n",
      "fbeta score of a logistic regression: 0.14135759272218337\n",
      "\n",
      "\n",
      "Target percentage: 0.25\n",
      "Accuracy score of a logistic regression: 0.9442295215897349\n",
      "f1 score of a logistic regression: 0.04209657449442839\n",
      "fbeta score of a logistic regression: 0.19308044081265466\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9148184636086215\n",
      "f1 score of a logistic regression: 0.03642294101658059\n",
      "fbeta score of a logistic regression: 0.24224958831531465\n",
      "\n",
      "\n",
      "Target percentage: 0.35\n",
      "Accuracy score of a logistic regression: 0.8866568950188625\n",
      "f1 score of a logistic regression: 0.03201313359326903\n",
      "fbeta score of a logistic regression: 0.2704614117000824\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.8422279356993536\n",
      "f1 score of a logistic regression: 0.028123149792776792\n",
      "fbeta score of a logistic regression: 0.3094063396859179\n",
      "\n",
      "\n",
      "Target percentage: 0.45\n",
      "Accuracy score of a logistic regression: 0.739265204123315\n",
      "f1 score of a logistic regression: 0.024278392230914485\n",
      "fbeta score of a logistic regression: 0.3854308005427408\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.6172958166134032\n",
      "f1 score of a logistic regression: 0.021262213482455602\n",
      "fbeta score of a logistic regression: 0.43113403079352547\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for percentage in [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]:\n",
    "    X_porct, y_porct = UnderSampling(X_train_, y_train, percentage, 42)\n",
    "    logreg.fit(X_porct, y_porct)\n",
    "    y_pred_log = logreg.predict(X_test_)\n",
    "    accuracy_logistic1=accuracy_score(y_test, y_pred_log)\n",
    "    f1_logistic1=f1_score(y_test,y_pred_log,average='binary')\n",
    "    fbs_logistic1=fbeta_score(y_test,y_pred_log,average='binary', beta = 10 )\n",
    "    print('Target percentage:',percentage)\n",
    "    print(\"Accuracy score of a logistic regression:\",accuracy_logistic1)\n",
    "    print(\"f1 score of a logistic regression:\", f1_logistic1)\n",
    "    print(\"fbeta score of a logistic regression:\", fbs_logistic1)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.977389047744912\n",
      "f1 score of a tree: 0.12465116279069767\n",
      "fbeta score of a tree: 0.2671535728385314\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9740490664872528\n",
      "f1 score of a tree: 0.09849749582637729\n",
      "fbeta score of a tree: 0.2341177857227046\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9505009971886489\n",
      "f1 score of a tree: 0.06955736224028906\n",
      "fbeta score of a tree: 0.2938154067021799\n",
      "\n",
      "\n",
      "Target percentage: 0.25\n",
      "Accuracy score of a tree: 0.941562342312036\n",
      "f1 score of a tree: 0.0681992337164751\n",
      "fbeta score of a tree: 0.33459892052856877\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9270250138164692\n",
      "f1 score of a tree: 0.06352143077397471\n",
      "fbeta score of a tree: 0.37831842315804787\n",
      "\n",
      "\n",
      "Target percentage: 0.35\n",
      "Accuracy score of a tree: 0.8940096595141409\n",
      "f1 score of a tree: 0.054853224769659314\n",
      "fbeta score of a tree: 0.4469953668487657\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.8964365523704255\n",
      "f1 score of a tree: 0.05357927097057533\n",
      "fbeta score of a tree: 0.42771356173418024\n",
      "\n",
      "\n",
      "Target percentage: 0.45\n",
      "Accuracy score of a tree: 0.8343945983612466\n",
      "f1 score of a tree: 0.03984396767901922\n",
      "fbeta score of a tree: 0.45948525435052323\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.7730975322584521\n",
      "f1 score of a tree: 0.030791337370419784\n",
      "fbeta score of a tree: 0.4456144479087005\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for percentage in [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]:\n",
    "    X_porct, y_porct = UnderSampling(X_train, y_train, percentage, 42)\n",
    "    tree.fit(X_porct, y_porct)\n",
    "    y_pred_tree = tree.predict(X_test)\n",
    "    accuracy_tree1=accuracy_score(y_test, y_pred_tree)\n",
    "    f1_tree1=f1_score(y_test,y_pred_tree,average='binary')\n",
    "    fbs_tree1=fbeta_score(y_test,y_pred_tree,average='binary', beta = 10 )\n",
    "    print('Target percentage:',percentage)\n",
    "    print(\"Accuracy score of a tree:\",accuracy_tree1)\n",
    "    print(\"f1 score of a tree:\", f1_tree1)\n",
    "    print(\"fbeta score of a tree:\", fbs_tree1)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor del porcentaje de balanceo adecuado es aquel que reporta el f1 score más alto. Para ambos casos, estos porcentajes son 10% y 15%.Los resultados de rendimiento mejoraron comparados con aquellos obtenidos en el ejercicio 15.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9914698320397914\n",
      "f1 score of a logistic regression: 0.037940379403794036\n",
      "fbeta score of a logistic regression: 0.028711825860948666\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9862315880529591\n",
      "f1 score of a logistic regression: 0.04975124378109452\n",
      "fbeta score of a logistic regression: 0.06094617426985274\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9778696205877406\n",
      "f1 score of a logistic regression: 0.051493305870236865\n",
      "fbeta score of a logistic regression: 0.10009513993498773\n",
      "\n",
      "\n",
      "Target percentage: 0.25\n",
      "Accuracy score of a logistic regression: 0.9658072422327414\n",
      "f1 score of a logistic regression: 0.04560697518443998\n",
      "fbeta score of a logistic regression: 0.1333799425153422\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9468726722252926\n",
      "f1 score of a logistic regression: 0.04409857328145266\n",
      "fbeta score of a logistic regression: 0.1938798554652213\n",
      "\n",
      "\n",
      "Target percentage: 0.35\n",
      "Accuracy score of a logistic regression: 0.9192637624047865\n",
      "f1 score of a logistic regression: 0.037800687285223365\n",
      "fbeta score of a logistic regression: 0.2402421883446859\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.8774779537208353\n",
      "f1 score of a logistic regression: 0.03152896486229819\n",
      "fbeta score of a logistic regression: 0.2839769647696477\n",
      "\n",
      "\n",
      "Target percentage: 0.45\n",
      "Accuracy score of a logistic regression: 0.7979431482326934\n",
      "f1 score of a logistic regression: 0.026848744358291866\n",
      "fbeta score of a logistic regression: 0.3561527237354085\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.6587211956652329\n",
      "f1 score of a logistic regression: 0.022572431353657697\n",
      "fbeta score of a logistic regression: 0.427061310782241\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for percentage in [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]:\n",
    "    X_porct, y_porct = OverSampling(X_train_, y_train, percentage, 42)\n",
    "    logreg.fit(X_porct, y_porct)\n",
    "    y_pred_log = logreg.predict(X_test_)\n",
    "    accuracy_logistic2=accuracy_score(y_test, y_pred_log)\n",
    "    f1_logistic2=f1_score(y_test,y_pred_log,average='binary')\n",
    "    fbs_logistic2=fbeta_score(y_test,y_pred_log,average='binary', beta = 10 )\n",
    "    print('Target percentage:',percentage)\n",
    "    print(\"Accuracy score of a logistic regression:\",accuracy_logistic2)\n",
    "    print(\"f1 score of a logistic regression:\", f1_logistic2)\n",
    "    print(\"fbeta score of a logistic regression:\", fbs_logistic2)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9846216690294831\n",
      "f1 score of a tree: 0.16010498687664043\n",
      "fbeta score of a tree: 0.24627253467642002\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9839248384073817\n",
      "f1 score of a tree: 0.12549019607843137\n",
      "fbeta score of a tree: 0.1937649880095923\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.969723910901795\n",
      "f1 score of a tree: 0.08959537572254335\n",
      "fbeta score of a tree: 0.24423729474628494\n",
      "\n",
      "\n",
      "Target percentage: 0.25\n",
      "Accuracy score of a tree: 0.9369488430208809\n",
      "f1 score of a tree: 0.06619217081850533\n",
      "fbeta score of a tree: 0.3470533899870682\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9373092726530023\n",
      "f1 score of a tree: 0.061848256023013304\n",
      "fbeta score of a tree: 0.3212753365882527\n",
      "\n",
      "\n",
      "Target percentage: 0.35\n",
      "Accuracy score of a tree: 0.8264651464545738\n",
      "f1 score of a tree: 0.04039330321551953\n",
      "fbeta score of a tree: 0.4830559139108272\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.8264651464545738\n",
      "f1 score of a tree: 0.04039330321551953\n",
      "fbeta score of a tree: 0.4830559139108272\n",
      "\n",
      "\n",
      "Target percentage: 0.45\n",
      "Accuracy score of a tree: 0.8274262921402311\n",
      "f1 score of a tree: 0.03983957219251337\n",
      "fbeta score of a tree: 0.4742082873798645\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8274262921402311\n",
      "f1 score of a tree: 0.03983957219251337\n",
      "fbeta score of a tree: 0.4742082873798645\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for percentage in [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]:\n",
    "    X_porct, y_porct = OverSampling(X_train_, y_train, percentage, 42)\n",
    "    tree.fit(X_porct, y_porct)\n",
    "    y_pred_tree = tree.predict(X_test_)\n",
    "    accuracy_tree2=accuracy_score(y_test, y_pred_tree)\n",
    "    f1_tree2=f1_score(y_test,y_pred_tree,average='binary')\n",
    "    fbs_tree2=fbeta_score(y_test,y_pred_tree,average='binary', beta = 10 )\n",
    "    print('Target percentage:',percentage)\n",
    "    print(\"Accuracy score of a tree:\",accuracy_tree2)\n",
    "    print(\"f1 score of a tree:\", f1_tree2)\n",
    "    print(\"fbeta score of a tree:\", fbs_tree2)\n",
    "    print('\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el porcentaje adecuado es 20% cuando se corre una regresión logística y 10% cuando se utiliza un árbol. Al igual que el numeral 15.2, los resultados en términos del f1 score son mejores comparados con aquellos del ejercicio 15.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9924790350097316\n",
      "f1 score of a logistic regression: 0.024922118380062308\n",
      "fbeta score of a logistic regression: 0.016438802083333336\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9894273974577696\n",
      "f1 score of a logistic regression: 0.03930131004366813\n",
      "fbeta score of a logistic regression: 0.03678226034880428\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.984885984093039\n",
      "f1 score of a logistic regression: 0.05697151424287856\n",
      "fbeta score of a logistic regression: 0.07700024075114358\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9719585746209481\n",
      "f1 score of a logistic regression: 0.044226044226044224\n",
      "fbeta score of a logistic regression: 0.1070419218087612\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9527116322656607\n",
      "f1 score of a logistic regression: 0.04651162790697675\n",
      "fbeta score of a logistic regression: 0.18420152741365556\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9266405555422063\n",
      "f1 score of a logistic regression: 0.03963510537905002\n",
      "fbeta score of a logistic regression: 0.2319384705110447\n",
      "\n",
      "\n",
      "6  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.992503063651873\n",
      "f1 score of a logistic regression: 0.025\n",
      "fbeta score of a logistic regression: 0.016439471007121058\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9895475406684768\n",
      "f1 score of a logistic regression: 0.039735099337748346\n",
      "fbeta score of a logistic regression: 0.036789703739679464\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.985006127303746\n",
      "f1 score of a logistic regression: 0.057401812688821746\n",
      "fbeta score of a logistic regression: 0.07701569209776458\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9717423168416752\n",
      "f1 score of a logistic regression: 0.04390243902439024\n",
      "fbeta score of a logistic regression: 0.10700412007062977\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9525914890549535\n",
      "f1 score of a logistic regression: 0.04639922667955534\n",
      "fbeta score of a logistic regression: 0.18416654003950766\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9264723550472163\n",
      "f1 score of a logistic regression: 0.03954802259887006\n",
      "fbeta score of a logistic regression: 0.23187930469006227\n",
      "\n",
      "\n",
      "7  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.992671264146863\n",
      "f1 score of a logistic regression: 0.025559105431309907\n",
      "fbeta score of a logistic regression: 0.016444154998371867\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9890669678256482\n",
      "f1 score of a logistic regression: 0.03805496828752642\n",
      "fbeta score of a logistic regression: 0.03675994823681657\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9844774971766346\n",
      "f1 score of a logistic regression: 0.05555555555555555\n",
      "fbeta score of a logistic regression: 0.0769477525161394\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9709974289352908\n",
      "f1 score of a logistic regression: 0.045849802371541494\n",
      "fbeta score of a logistic regression: 0.11477272727272726\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9516784006535791\n",
      "f1 score of a logistic regression: 0.045562411010916\n",
      "fbeta score of a logistic regression: 0.18390106972156892\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9253910661508518\n",
      "f1 score of a logistic regression: 0.03899721448467967\n",
      "fbeta score of a logistic regression: 0.23149967256057627\n",
      "\n",
      "\n",
      "8  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9925511209361559\n",
      "f1 score of a logistic regression: 0.025157232704402517\n",
      "fbeta score of a logistic regression: 0.01644080901802792\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9895235120263354\n",
      "f1 score of a logistic regression: 0.03964757709251102\n",
      "fbeta score of a logistic regression: 0.03678821482051075\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.985006127303746\n",
      "f1 score of a logistic regression: 0.05454545454545455\n",
      "fbeta score of a logistic regression: 0.07296809151113787\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9715741163466852\n",
      "f1 score of a logistic regression: 0.04519774011299435\n",
      "fbeta score of a logistic regression: 0.11092806150466775\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9522550880649735\n",
      "f1 score of a logistic regression: 0.04700239808153477\n",
      "fbeta score of a logistic regression: 0.18788914198936976\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.925511209361559\n",
      "f1 score of a logistic regression: 0.040247678018575844\n",
      "fbeta score of a logistic regression: 0.2388575586683646\n",
      "\n",
      "\n",
      "9  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9924550063675902\n",
      "f1 score of a logistic regression: 0.02484472049689441\n",
      "fbeta score of a logistic regression: 0.016438133213980553\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9889948818992239\n",
      "f1 score of a logistic regression: 0.04583333333333333\n",
      "fbeta score of a logistic regression: 0.04491611077420658\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9843092966816446\n",
      "f1 score of a logistic regression: 0.05224963715529753\n",
      "fbeta score of a logistic regression: 0.07288325849903785\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9704687988081794\n",
      "f1 score of a logistic regression: 0.04357976653696498\n",
      "fbeta score of a logistic regression: 0.11072826938136257\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9516543720114377\n",
      "f1 score of a logistic regression: 0.04554079696394687\n",
      "fbeta score of a logistic regression: 0.18389409399537232\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9258235817093976\n",
      "f1 score of a logistic regression: 0.039215686274509796\n",
      "fbeta score of a logistic regression: 0.23165137614678893\n",
      "\n",
      "\n",
      "10  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.992503063651873\n",
      "f1 score of a logistic regression: 0.025\n",
      "fbeta score of a logistic regression: 0.016439471007121058\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9891871110363554\n",
      "f1 score of a logistic regression: 0.038461538461538464\n",
      "fbeta score of a logistic regression: 0.03676738259919912\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9845976403873418\n",
      "f1 score of a logistic regression: 0.055964653902798235\n",
      "fbeta score of a logistic regression: 0.07696318280259885\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9710695148617151\n",
      "f1 score of a logistic regression: 0.04595879556259905\n",
      "fbeta score of a logistic regression: 0.1147862209507387\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9515342288007305\n",
      "f1 score of a logistic regression: 0.04633569739952719\n",
      "fbeta score of a logistic regression: 0.1876753886992795\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9257034384986904\n",
      "f1 score of a logistic regression: 0.039154754505904284\n",
      "fbeta score of a logistic regression: 0.23160921632147924\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5,6,7,8,9,10]: # número de vecinos más cercanos\n",
    "    print(k,' vecinos:')\n",
    "    for percentage in [0.1,0.15,0.2,0.3,0.4,0.5]:\n",
    "        smote = SMOTE(percentage,random_state=42, k_neighbors = k)\n",
    "        X_porct, y_porct = smote.fit_resample(X_train_, y_train)\n",
    "        logreg.fit(X_porct, y_porct)\n",
    "        y_pred_log = logreg.predict(X_test_)\n",
    "        accuracy_logistic3=accuracy_score(y_test, y_pred_log)\n",
    "        f1_logistic3=f1_score(y_test,y_pred_log,average='binary')\n",
    "        fbs_logistic3=fbeta_score(y_test,y_pred_log,average='binary', beta = 10 )\n",
    "        print('Target percentage:',percentage)\n",
    "        print(\"Accuracy score of a logistic regression:\",accuracy_logistic3)\n",
    "        print(\"f1 score of a logistic regression:\", f1_logistic3)\n",
    "        print(\"fbeta score of a logistic regression:\", fbs_logistic3)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el fbeta score se maximiza (0.2388) cuando se utilizan 8 vecinos más cercanos y un porcentaje de balanceo igual al 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9919023475983372\n",
      "f1 score of a tree: 0.07162534435261707\n",
      "fbeta score of a tree: 0.05333495816069543\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9864238171900905\n",
      "f1 score of a tree: 0.13740458015267176\n",
      "fbeta score of a tree: 0.18245684464070652\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9863997885479492\n",
      "f1 score of a tree: 0.13719512195121952\n",
      "fbeta score of a tree: 0.18244952029224037\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9611456856573035\n",
      "f1 score of a tree: 0.05714285714285715\n",
      "fbeta score of a tree: 0.19056603773584904\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9410337121849244\n",
      "f1 score of a tree: 0.061208875286916604\n",
      "fbeta score of a tree: 0.3007182998995125\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8152918278588077\n",
      "f1 score of a tree: 0.03417514763161202\n",
      "fbeta score of a tree: 0.4263984602967653\n",
      "\n",
      "\n",
      "6  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9874089915178893\n",
      "f1 score of a tree: 0.1437908496732026\n",
      "fbeta score of a tree: 0.1787107411428801\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9866400749693635\n",
      "f1 score of a tree: 0.13931888544891644\n",
      "fbeta score of a tree: 0.18252279024938758\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9860874162001105\n",
      "f1 score of a tree: 0.1345291479820628\n",
      "fbeta score of a tree: 0.18235435724602791\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9606651128144749\n",
      "f1 score of a tree: 0.060814687320711415\n",
      "fbeta score of a tree: 0.20590045388106776\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9422591729341375\n",
      "f1 score of a tree: 0.06096131301289565\n",
      "fbeta score of a tree: 0.2938017453569031\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8523199653987553\n",
      "f1 score of a tree: 0.03908692933083177\n",
      "fbeta score of a tree: 0.41189520733418156\n",
      "\n",
      "\n",
      "7  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9903404858591441\n",
      "f1 score of a tree: 0.08636363636363636\n",
      "fbeta score of a tree: 0.07770803806438549\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9865439604007977\n",
      "f1 score of a tree: 0.13846153846153844\n",
      "fbeta score of a tree: 0.18249347520578196\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9857029579258476\n",
      "f1 score of a tree: 0.1414141414141414\n",
      "fbeta score of a tree: 0.19837261503928172\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9586226782324531\n",
      "f1 score of a tree: 0.07717041800643087\n",
      "fbeta score of a tree: 0.2783966923165269\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9414662277434702\n",
      "f1 score of a tree: 0.060185185185185196\n",
      "fbeta score of a tree: 0.2934406078891496\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8822115962226974\n",
      "f1 score of a tree: 0.027766759222530742\n",
      "fbeta score of a tree: 0.24132163702768203\n",
      "\n",
      "\n",
      "8  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9903164572170027\n",
      "f1 score of a tree: 0.08616780045351474\n",
      "fbeta score of a tree: 0.07770489148040167\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9866400749693635\n",
      "f1 score of a tree: 0.13931888544891644\n",
      "fbeta score of a tree: 0.18252279024938758\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9590311651488574\n",
      "f1 score of a tree: 0.06060606060606061\n",
      "fbeta score of a tree: 0.2130801687763713\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9422591729341375\n",
      "f1 score of a tree: 0.06096131301289565\n",
      "fbeta score of a tree: 0.2938017453569031\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.883076627339789\n",
      "f1 score of a tree: 0.027966440271673988\n",
      "fbeta score of a tree: 0.2416185366187075\n",
      "\n",
      "\n",
      "9  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9864959031165149\n",
      "f1 score of a tree: 0.06333333333333334\n",
      "fbeta score of a tree: 0.07720780527056931\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.990052142153447\n",
      "f1 score of a tree: 0.084070796460177\n",
      "fbeta score of a tree: 0.07767029586756789\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.990052142153447\n",
      "f1 score of a tree: 0.084070796460177\n",
      "fbeta score of a tree: 0.07767029586756789\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8831487132662134\n",
      "f1 score of a tree: 0.027983210073955628\n",
      "fbeta score of a tree: 0.24164331123111624\n",
      "\n",
      "\n",
      "10  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9903164572170027\n",
      "f1 score of a tree: 0.08616780045351474\n",
      "fbeta score of a tree: 0.07770489148040167\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9847177835980488\n",
      "f1 score of a tree: 0.13821138211382114\n",
      "fbeta score of a tree: 0.20609770735806027\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9598241103395247\n",
      "f1 score of a tree: 0.0617283950617284\n",
      "fbeta score of a tree: 0.21335023236163922\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9900761707955883\n",
      "f1 score of a tree: 0.08425720620842572\n",
      "fbeta score of a tree: 0.07767343965028738\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8830045414133647\n",
      "f1 score of a tree: 0.027949690556997406\n",
      "fbeta score of a tree: 0.24159376708583927\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5,6,7,8,9,10]: #número de vecinos\n",
    "    print(k,' vecinos:')\n",
    "    for percentage in [0.1,0.15,0.2,0.3,0.4,0.5]:\n",
    "        smote = SMOTE(percentage,random_state=42, k_neighbors = k)\n",
    "        X_porct, y_porct = smote.fit_resample(X_train_, y_train)\n",
    "        tree.fit(X_porct, y_porct)\n",
    "        y_pred_tree = tree.predict(X_test_)\n",
    "        accuracy_tree3=accuracy_score(y_test, y_pred_tree)\n",
    "        f1_tree3=f1_score(y_test,y_pred_tree,average='binary')\n",
    "        fbs_tree3=fbeta_score(y_test,y_pred_tree,average='binary', beta = 10 )\n",
    "        print('Target percentage:',percentage)\n",
    "        print(\"Accuracy score of a tree:\",accuracy_tree3)\n",
    "        print(\"f1 score of a tree:\", f1_tree3)\n",
    "        print(\"fbeta score of a tree:\", fbs_tree3)\n",
    "        print('\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el fbeta score se maximiza (0.42) cuando se utilizan 5 vecinos más cercanos y un porcentaje de balanceo igual al 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9928875219261359\n",
      "f1 score of a logistic regression: 0.019867549668874173\n",
      "fbeta score of a logistic regression: 0.012338640713442196\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.990052142153447\n",
      "f1 score of a logistic regression: 0.05045871559633028\n",
      "fbeta score of a logistic regression: 0.04499615244421044\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.985390585578009\n",
      "f1 score of a logistic regression: 0.05000000000000001\n",
      "fbeta score of a logistic regression: 0.06491263305884716\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.972727491169474\n",
      "f1 score of a logistic regression: 0.04380791912384162\n",
      "fbeta score of a logistic regression: 0.10321515604119173\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.954009178941298\n",
      "f1 score of a logistic regression: 0.043\n",
      "fbeta score of a logistic regression: 0.16541611121691108\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9282985318499651\n",
      "f1 score of a logistic regression: 0.04113110539845759\n",
      "fbeta score of a logistic regression: 0.23619687945335627\n",
      "\n",
      "\n",
      "6  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9927914073575702\n",
      "f1 score of a logistic regression: 0.025974025974025972\n",
      "fbeta score of a logistic regression: 0.01644750234091927\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9899079703005983\n",
      "f1 score of a logistic regression: 0.04545454545454545\n",
      "fbeta score of a logistic regression: 0.04089896740230817\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9853665569358675\n",
      "f1 score of a logistic regression: 0.05287713841368585\n",
      "fbeta score of a logistic regression: 0.06896136235842235\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9734243217915756\n",
      "f1 score of a logistic regression: 0.043252595155709346\n",
      "fbeta score of a logistic regression: 0.09936641611900358\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9538650070884495\n",
      "f1 score of a logistic regression: 0.04287138584247258\n",
      "fbeta score of a logistic regression: 0.1653783176573626\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.928731047408511\n",
      "f1 score of a logistic regression: 0.040750323415265195\n",
      "fbeta score of a logistic regression: 0.232676344754452\n",
      "\n",
      "\n",
      "7  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9927914073575702\n",
      "f1 score of a logistic regression: 0.025974025974025972\n",
      "fbeta score of a logistic regression: 0.01644750234091927\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9899800562270226\n",
      "f1 score of a logistic regression: 0.04576659038901602\n",
      "fbeta score of a logistic regression: 0.04090393649765106\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9853184996515847\n",
      "f1 score of a logistic regression: 0.05271317829457364\n",
      "fbeta score of a logistic regression: 0.0689558232931727\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9732320926544441\n",
      "f1 score of a logistic regression: 0.0429553264604811\n",
      "fbeta score of a logistic regression: 0.09933514300326529\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9537208352356008\n",
      "f1 score of a logistic regression: 0.042743538767395624\n",
      "fbeta score of a logistic regression: 0.16534054136368828\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9283706177763894\n",
      "f1 score of a logistic regression: 0.040553588670743476\n",
      "fbeta score of a logistic regression: 0.23254879029310724\n",
      "\n",
      "\n",
      "8  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9927193214311459\n",
      "f1 score of a logistic regression: 0.02572347266881029\n",
      "fbeta score of a logistic regression: 0.016445493771879836\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9897397698056083\n",
      "f1 score of a logistic regression: 0.04899777282850779\n",
      "fbeta score of a logistic regression: 0.04497247409326424\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9851983564408775\n",
      "f1 score of a logistic regression: 0.052307692307692305\n",
      "fbeta score of a logistic regression: 0.06894197952218428\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9729677775908884\n",
      "f1 score of a logistic regression: 0.0425531914893617\n",
      "fbeta score of a logistic regression: 0.09929217459693279\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9534805488141865\n",
      "f1 score of a logistic regression: 0.04253214638971315\n",
      "fbeta score of a logistic regression: 0.1652776192107166\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9283946464185309\n",
      "f1 score of a logistic regression: 0.04056664520283322\n",
      "fbeta score of a logistic regression: 0.2325572895727495\n",
      "\n",
      "\n",
      "9  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9927193214311459\n",
      "f1 score of a logistic regression: 0.019417475728155338\n",
      "fbeta score of a logistic regression: 0.012335124572545188\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.9897157411634668\n",
      "f1 score of a logistic regression: 0.048888888888888885\n",
      "fbeta score of a logistic regression: 0.044970653713823104\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.985054184588029\n",
      "f1 score of a logistic regression: 0.054711246200607896\n",
      "fbeta score of a logistic regression: 0.07297394934371614\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9731119494437369\n",
      "f1 score of a logistic regression: 0.0444064901793339\n",
      "fbeta score of a logistic regression: 0.10328010697711004\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9531922051084893\n",
      "f1 score of a logistic regression: 0.04133858267716536\n",
      "fbeta score of a logistic regression: 0.16137254156046715\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.9278900449335608\n",
      "f1 score of a logistic regression: 0.040294211704509114\n",
      "fbeta score of a logistic regression: 0.2323789350668322\n",
      "\n",
      "\n",
      "10  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a logistic regression: 0.9926952927890045\n",
      "f1 score of a logistic regression: 0.02564102564102564\n",
      "fbeta score of a logistic regression: 0.016444824357878456\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a logistic regression: 0.990052142153447\n",
      "f1 score of a logistic regression: 0.046082949308755755\n",
      "fbeta score of a logistic regression: 0.04090890680059945\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a logistic regression: 0.9853184996515847\n",
      "f1 score of a logistic regression: 0.05564142194744977\n",
      "fbeta score of a logistic regression: 0.07300618424222954\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a logistic regression: 0.9726554052430497\n",
      "f1 score of a logistic regression: 0.04369747899159664\n",
      "fbeta score of a logistic regression: 0.1032029868343486\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a logistic regression: 0.9540332075834395\n",
      "f1 score of a logistic regression: 0.04302151075537768\n",
      "fbeta score of a logistic regression: 0.1654224118229603\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a logistic regression: 0.927625729870005\n",
      "f1 score of a logistic regression: 0.04015296367112811\n",
      "fbeta score of a logistic regression: 0.23228562041397433\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5,6,7,8,9,10]: # número de vecinos más cercanos\n",
    "    print(k,' vecinos:')\n",
    "    for percentage in [0.1,0.15,0.2,0.3,0.4,0.5]:\n",
    "        adasyn = ADASYN(percentage,random_state=42, n_neighbors = k)\n",
    "        X_porct, y_porct = adasyn.fit_resample(X_train_, y_train)\n",
    "        logreg.fit(X_porct, y_porct)\n",
    "        y_pred_log = logreg.predict(X_test_)\n",
    "        accuracy_logistic4=accuracy_score(y_test, y_pred_log)\n",
    "        f1_logistic4=f1_score(y_test,y_pred_log,average='binary')\n",
    "        fbs_logistic4=fbeta_score(y_test,y_pred_log,average='binary', beta = 10 )\n",
    "        print('Target percentage:',percentage)\n",
    "        print(\"Accuracy score of a logistic regression:\",accuracy_logistic4)\n",
    "        print(\"f1 score of a logistic regression:\", f1_logistic4)\n",
    "        print(\"fbeta score of a logistic regression:\", fbs_logistic4)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el fbeta score se maximiza (0.2361) cuando se utilizan 5 vecinos más cercanos y un porcentaje de balanceo igual al 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9869524473172021\n",
      "f1 score of a tree: 0.13946117274167988\n",
      "fbeta score of a tree: 0.17857429880253956\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9826753490160272\n",
      "f1 score of a tree: 0.05504587155963303\n",
      "fbeta score of a tree: 0.08477895914941243\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9743614388350914\n",
      "f1 score of a tree: 0.11305070656691606\n",
      "fbeta score of a tree: 0.26977767303008876\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.8972294975610928\n",
      "f1 score of a tree: 0.03169572107765452\n",
      "fbeta score of a tree: 0.24658203125\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8569094360477689\n",
      "f1 score of a tree: 0.027437530622243998\n",
      "fbeta score of a tree: 0.279281058660873\n",
      "\n",
      "\n",
      "6  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9903164572170027\n",
      "f1 score of a tree: 0.08616780045351474\n",
      "fbeta score of a tree: 0.07770489148040167\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9826272917317442\n",
      "f1 score of a tree: 0.05490196078431373\n",
      "fbeta score of a tree: 0.08477218225419665\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9783261647884278\n",
      "f1 score of a tree: 0.04449152542372881\n",
      "fbeta score of a tree: 0.08417000674629946\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9099406492539107\n",
      "f1 score of a tree: 0.030522503879979304\n",
      "fbeta score of a tree: 0.2119056932541517\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8570055506163347\n",
      "f1 score of a tree: 0.027455466579506458\n",
      "fbeta score of a tree: 0.2793178376242839\n",
      "\n",
      "\n",
      "7  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9869524473172021\n",
      "f1 score of a tree: 0.13946117274167988\n",
      "fbeta score of a tree: 0.17857429880253956\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.987168705096475\n",
      "f1 score of a tree: 0.07612456747404844\n",
      "fbeta score of a tree: 0.08947771111021625\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.978446307999135\n",
      "f1 score of a tree: 0.1248780487804878\n",
      "fbeta score of a tree: 0.2556962025316456\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9082826729461518\n",
      "f1 score of a tree: 0.029987293519695042\n",
      "fbeta score of a tree: 0.21138701667257892\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8559002330778288\n",
      "f1 score of a tree: 0.027250608272506083\n",
      "fbeta score of a tree: 0.27889546351084815\n",
      "\n",
      "\n",
      "8  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9866400749693635\n",
      "f1 score of a tree: 0.13931888544891644\n",
      "fbeta score of a tree: 0.18252279024938758\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9858711584208376\n",
      "f1 score of a tree: 0.1144578313253012\n",
      "fbeta score of a tree: 0.1540190216300815\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9859913016315448\n",
      "f1 score of a tree: 0.08763693270735524\n",
      "fbeta score of a tree: 0.11360167108540212\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.990052142153447\n",
      "f1 score of a tree: 0.084070796460177\n",
      "fbeta score of a tree: 0.07767029586756789\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.9098925919696278\n",
      "f1 score of a tree: 0.03050672182006205\n",
      "fbeta score of a tree: 0.21189062333321482\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8810822500420501\n",
      "f1 score of a tree: 0.027510316368638238\n",
      "fbeta score of a tree: 0.24093511450381677\n",
      "\n",
      "\n",
      "9  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9899319989427398\n",
      "f1 score of a tree: 0.12159329140461216\n",
      "fbeta score of a tree: 0.11842956493611516\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9826513203738857\n",
      "f1 score of a tree: 0.05497382198952879\n",
      "fbeta score of a tree: 0.08477557056636956\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9859913016315448\n",
      "f1 score of a tree: 0.08763693270735524\n",
      "fbeta score of a tree: 0.11360167108540212\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9859913016315448\n",
      "f1 score of a tree: 0.08763693270735524\n",
      "fbeta score of a tree: 0.11360167108540212\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.8984309296681644\n",
      "f1 score of a tree: 0.03205862147927639\n",
      "fbeta score of a tree: 0.24701278736636156\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8844943172261336\n",
      "f1 score of a tree: 0.027906976744186046\n",
      "fbeta score of a tree: 0.23866438356164382\n",
      "\n",
      "\n",
      "10  vecinos:\n",
      "Target percentage: 0.1\n",
      "Accuracy score of a tree: 0.9893312828892039\n",
      "f1 score of a tree: 0.112\n",
      "fbeta score of a tree: 0.11423954756614825\n",
      "\n",
      "\n",
      "Target percentage: 0.15\n",
      "Accuracy score of a tree: 0.9859913016315448\n",
      "f1 score of a tree: 0.08763693270735524\n",
      "fbeta score of a tree: 0.11360167108540212\n",
      "\n",
      "\n",
      "Target percentage: 0.2\n",
      "Accuracy score of a tree: 0.9859913016315448\n",
      "f1 score of a tree: 0.08763693270735524\n",
      "fbeta score of a tree: 0.11360167108540212\n",
      "\n",
      "\n",
      "Target percentage: 0.3\n",
      "Accuracy score of a tree: 0.9900761707955883\n",
      "f1 score of a tree: 0.08425720620842572\n",
      "fbeta score of a tree: 0.07767343965028738\n",
      "\n",
      "\n",
      "Target percentage: 0.4\n",
      "Accuracy score of a tree: 0.990052142153447\n",
      "f1 score of a tree: 0.084070796460177\n",
      "fbeta score of a tree: 0.07767029586756789\n",
      "\n",
      "\n",
      "Target percentage: 0.5\n",
      "Accuracy score of a tree: 0.8570055506163347\n",
      "f1 score of a tree: 0.027455466579506458\n",
      "fbeta score of a tree: 0.2793178376242839\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5,6,7,8,9,10]: #número de vecinos\n",
    "    print(k,' vecinos:')\n",
    "    for percentage in [0.1,0.15,0.2,0.3,0.4,0.5]:\n",
    "        adasyn = ADASYN(percentage,random_state=42, n_neighbors = k)\n",
    "        X_porct, y_porct = adasyn.fit_resample(X_train_, y_train)\n",
    "        tree.fit(X_porct, y_porct)\n",
    "        y_pred_tree = tree.predict(X_test_)\n",
    "        accuracy_tree4=accuracy_score(y_test, y_pred_tree)\n",
    "        f1_tree4=f1_score(y_test,y_pred_tree,average='binary')\n",
    "        fbs_tree4=fbeta_score(y_test,y_pred_tree,average='binary', beta = 10 )\n",
    "        print('Target percentage:',percentage)\n",
    "        print(\"Accuracy score of a tree:\",accuracy_tree4)\n",
    "        print(\"f1 score of a tree:\", f1_tree4)\n",
    "        print(\"fbeta score of a tree:\", fbs_tree4)\n",
    "        print('\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el fbeta score se maximiza (0.2793) cuando se utilizan 6 o 10 vecinos más cercanos y un porcentaje de balanceo igual al 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. El árbol reporta mejores resultados y métricas de rendimiento que la regresión logística.\n",
    "2. Cuando se usó undersampling, el porcentaje de balanceo adecuado fue igual al 15% en ambos casos.\n",
    "3. Cuando se usó oversampling el porcentaje adecuado fue 20% cuando se corre una regresión logística y 10% cuando se utilizó un árbol.\n",
    "4. Cuando se usó la función SMOTE, el fbeta score se maximiza cuando se utiliza un porcentaje de balanceo igual al 50%, y 8 vecinos más cercanos para el caso de la regresión logística, y 5 cuando se utiliza un arbol de decisión.  \n",
    "5. Cuando se usó la función ADASYN, el fbeta score se maximiza cuando se utiliza un porcentaje de balanceo igual al 50%, y 5 vecinos más cercanos para el caso de la regresión logística, y 6 O 10 cuando se utiliza un arbol de decisión.  \n",
    "6. Cuando se utilizó la función ADASYN, el fbeta score no cambió mucho a medida que cambiaba el número de vecinos más cercanos, manteniendo el porcentaje de balanceo en 50%.\n",
    "7. Implementar la función ADASYN requiere tiempo de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
